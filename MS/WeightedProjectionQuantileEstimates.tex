\documentclass{article}
\usepackage{amssymb,amsmath,graphicx,color,multicol,mycommands}
\usepackage{amsfonts}
\usepackage{algorithm,url}
\usepackage[noend]{algpseudocode}
\usepackage{epsfig,latexsym,graphicx}
\parindent 0in

\title{Weighted Projection Quantiles Algorithm}


\begin{document}
\maketitle

\paragraph{Algorithm to calculate weighted projection quantile} along the vector $\bfu \in\mathcal B_p$, given a set of observations $\bfX_1,\bfX_2,...,\bfX_n$:

\begin{enumerate}

\item \textbf{\textit{Compute $Q_{proj}(\bfu)$, the projection quantile along $\bfu$}}

\begin{itemize}
\item Project each $\bfX_i$ along $\bfu$ to obtain $X_{\bfu i}=\frac{\langle\bfX_i,\bfu\rangle}{\|\bfu\|}$, for $i=1,2,...,n$.
\item Find $\alpha=\frac{1+\|\bfu\|}{2}$-th quantile of $X_{\bfu 1},...,X_{\bfu n}$, say $q_\bfu$..
\item $Q_{proj}(\bfu)=q_\bfu\bfe_\bfu$, $\bfe_\bfu=\bfu/\|\bfu\|$ being the unit vector along $\bfu$.

\end{itemize}

\item \textit{\textbf{Compute Weights corresponding to this projection quantile $Q_{proj}(\bfu)$}}

\begin{itemize}

\item Compute global weights for the direction vector $\bfu$ by $k$-mean distance:

\begin{itemize}
\item Compute $k$-mean distance corresponding to $Q_{proj}(\bfu)$ using $\bar d_k=\frac{1}{n}\sum_{i=1}^nd_i\mathbb{I}_{\{d_i<d_{(k)}\}}$, where $d_i$ is the euclidean distace of $\bfX_i$ from $Q_{proj}(\bfu)$ given by $\|\bfX_i-Q_{proj}(\bfu)\|$. $k$ is a tuning parameter.\\

\item Compute the weights corresponding to $\bfu$:
$$w_\bfu=\exp(-a.d_k)$$
where $a$ is a tuning parameter. 
\end{itemize}

\item Compute weights for each sample point $\bfX_i; i=1,2,...,n$:

\begin{itemize}
\item Compute the orthogonal Norms by $\|\bfX_{\bfu\perp i}\|=\|\bfX_i-X_{\bfu i}\bfe_\bfu\|$.

\item Compute weight of $i^{th}$ sample:
$$w_{2i} = \exp\left[-b\frac{\|\bfX_{\bfu\perp i}\|}{\|\bfX_i\|}\right]\mathbb{I}_{\{\|\bfX_{\bfu\perp i}\|\leq\epsilon\}}$$
$b,\epsilon$ being tuning parameters.
\end{itemize}
\end{itemize} 

\item \textit{\textbf{Compute the weighted projection quantile}}
\begin{itemize}
\item Suppose there are $m$ observations with non-zero weights $w_{2i}$, with indices $i_1,i_2,...,i_m$. Define $\tilde X_{\bfu i_j} = w_\bfu w_{2i_j}X_{\bfu i_j}$.
\item Find $\alpha=\frac{1+\|\bfu\|}{2}$-th quantile of $\tilde X_{\bfu i_1},...,\tilde X_{\bfu i_m}$. Let it be $\tilde q_\bfu$.
\item Find the weighted projection quantile as $\tilde Q_{proj}(\bfu)=\tilde q_\bfu\bfe_\bfu$.
\end{itemize}
\end{enumerate}
\newpage

\paragraph{Definition} Given a random vector $\bfX\in \mathbb{R}^p$ that follows a multivariate distribution $F$, and a point $\bfp\in\mathbb{R}^p$, find $\alpha_\bfp$ such that $\|\bfp\|$ is the $\alpha_\bfp$-th quantile for the projection of $\bfX$ on $\bfp$, say $X_\bfp$. Then the \textbf{Projection Quantile Depth} (PQD) at $\bfp$ with respect to $F$ is defined as
$$ D(\bfp, F) = \exp(-\alpha_\bfp) $$

\paragraph{} Given data $\bfX_1,\bfX_2,...,\bfX_n$, the PQD at a given $\bfp$ can be estimated by finding the two nearest points on either side of $\|\bfp\|$ along $\bfp$, say $\bfp_1, \bfp_2$, obtain their corresponding quantiles, say $\alpha_1, \alpha_2$ respectively, then estimate $\alpha_\bfp$ by a linear approximation:
$$\hat\alpha_\bfp=\frac{(\alpha_1-\alpha_2)(\|\bfp\|-\|\bfp_1\|)}{\|\bfp_1\|-\|\bfp_2\|}+\alpha_1$$
and plugging it in the above definition.

\begin{algorithm}[h]
\caption{Algorithm for PQD-based classification}
\begin{algorithmic}[1]
\Procedure{PQDClassifier}{training data $\bfX_i \in\mathbb{R}^{n_i\times p}$ with class labels $i$; $i=1,2,...,k$, new data $\bfx_{new}\in\mathbb{R}^p$}
\State Set $i=1$.
\State \emph{top}:
\State Estimate from the sample the PQD of $\bfp$ with respect to the $i^{th}$ population, say $D(\bfx_{new},\bfX_i)$.
\If {$i=k$} \textbf{Stop}
	\Else \State Set $i\leftarrow i+1$, \textbf{goto} \emph{top}
\EndIf
\\
\State Find $c$ that maximizes the PQD of $\bfx_{new}$ w.r.t. all possible classes:
$$ D(\bfx_{new},\bfX_c) = \max\{D(\bfx_{new},\bfX_i): i=1,2,...,k\} $$
\State Assign class $c$ to new data $\bfx_{new}$.

\EndProcedure
\end{algorithmic}
\end{algorithm}

\paragraph{Note} One can define a weighted version of PQD by replacing $X_\bfp$ by their weighted version $\tilde X_\bfp$. A weighted classification scheme follows similarly.

\section*{Modifications}
\paragraph{1. $w_{2i}=\mathbb{I}_{\{\|X_{\bfu\perp i}\|\leq\epsilon\}}$}
Wouldn't work. The objective function here is
\begin{eqnarray*}
\tilde\Psi_\bfu(q) &=& \mathbb{E}\left[\lbrace |X_\bfu-q|+\alpha(X_\bfu-q)\rbrace\mathbb{I}_{\{\|\bfX_{\bfu\perp}\|\leq\epsilon\}}\right]\\
&=&\mathbb{E}\left[|X_\bfu-q|+\alpha(X_\bfu-q)\right]P\left[\|\bfX_{\bfu\perp}\|\leq\epsilon\right]\\
&=&\Psi_\bfu(q)P\left[\|\bfX_{\bfu\perp}\|\leq\epsilon\right]
\end{eqnarray*}
because $Cov(X_\bfu\bfe_\bfu,\bfX_{\bfu\perp})=\bf{0}$. Hence it gives out PQ as the minimizer.
\end{document}