else{
beta = as.matrix(glmnet.model$beta[index,])
}
sumcoefs = apply(abs(beta), 2, sum)
glmnet.model$lambda[min(which(sumcoefs>0))]
}
n = 100; p = 50
v.star = 1
beta.star = c(sample(1:10, 10, replace=T), rep(0,40))
Sigma = diag(p)
X = my.mvrnorm(n=n, mu=rep(0,p), Sigma=Sigma)
y = my.mvrnorm(n=1, mu=rep(0,100)+X%*%beta.star, Sigma=v.star*diag(100))
# apply LASSO
index.vec = 11:30
mod1 = glmnet(X,y)
(true.lam = lambda.fnzero(mod1, index=index.vec))
# consider permutations
nperm = 1000
lam.vec = rep(0, nperm)
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
hist(lam.vec, xlim=c(0,max(lam.vec, true.lam)))
abline(v=true.lam, lwd=2, col="Red")
(pval = sum(true.lam<lam.vec)/nperm)
n = 100; p = 50
v.star = 1
beta.star = c(rep(0,50))
Sigma = diag(p)
X = my.mvrnorm(n=n, mu=rep(0,p), Sigma=Sigma)
y = my.mvrnorm(n=1, mu=rep(0,100)+X%*%beta.star, Sigma=v.star*diag(100))
# apply LASSO
index.vec = 11:30
mod1 = glmnet(X,y)
(true.lam = lambda.fnzero(mod1, index=index.vec))
nperm = 1000
lam.vec = rep(0, nperm)
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
hist(lam.vec, xlim=c(0,max(lam.vec, true.lam)))
abline(v=true.lam, lwd=2, col="Red")
(pval = sum(true.lam<lam.vec)/nperm)
imod1
View(as.matrix(imod1$beta))
n = 100; p = 50
v.star = 1
beta.star = c(sample(1:10, 10, replace=T), rep(0,40))
Sigma = diag(p)
X = my.mvrnorm(n=n, mu=rep(0,p), Sigma=Sigma)
y = my.mvrnorm(n=1, mu=rep(0,100)+X%*%beta.star, Sigma=v.star*diag(100))
beta.star
y
index.vec = 11:30
mod1 = glmnet(X,y)
(true.lam = lambda.fnzero(mod1, index=index.vec))
nperm = 1000
lam.vec = rep(0, nperm)
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
hist(lam.vec, xlim=c(0,max(lam.vec, true.lam)))
index.vec = 1:10
nperm = 1000
lam.vec = rep(0, nperm)
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
hist(lam.vec, xlim=c(0,max(lam.vec, true.lam)))
index.vec = 1:50
mod1 = glmnet(X,y)
(true.lam = lambda.fnzero(mod1, index=index.vec))
nperm = 1000
lam.vec = rep(0, nperm)
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
hist(lam.vec, xlim=c(0,max(lam.vec, true.lam)))
mean(beta(1:10))
mean(beta[1:10
]
)
mean(beta.star[1:10])
n = 100; p = 50
v.star = 1
beta.star = c(sample(0, 10, replace=T), rep(0,40))
Sigma = diag(p)
X = my.mvrnorm(n=n, mu=rep(0,p), Sigma=Sigma)
y = my.mvrnorm(n=1, mu=rep(5,100)+X%*%beta.star, Sigma=v.star*diag(100))
# apply LASSO
index.vec = 1:50
mod1 = glmnet(X,y)
(true.lam = lambda.fnzero(mod1, index=index.vec))
nperm = 1000
lam.vec = rep(0, nperm)
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
hist(lam.vec, xlim=c(0,max(lam.vec, true.lam)))
abline(v=true.lam, lwd=2, col="Red")
(pval = sum(true.lam<lam.vec)/nperm)
n = 100; p = 50
v.star = 1
beta.star = c(sample(0, 10, replace=T), rep(0,40))
Sigma = diag(p)
X = my.mvrnorm(n=n, mu=rep(0,p), Sigma=Sigma)
y = my.mvrnorm(n=1, mu=rep(0,100)+X%*%beta.star, Sigma=v.star*diag(100))
# apply LASSO
index.vec = 1:50
mod1 = glmnet(X,y)
(true.lam = lambda.fnzero(mod1, index=index.vec))
nperm = 1000
lam.vec = rep(0, nperm)
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
hist(lam.vec, xlim=c(0,max(lam.vec, true.lam)))
abline(v=true.lam, lwd=2, col="Red")
(pval = sum(true.lam<lam.vec)/nperm)
n = 100; p = 50
v.star = 1
beta.star = c(sample(1:10, 10, replace=T), rep(0,40))
Sigma = diag(p)
X = my.mvrnorm(n=n, mu=rep(0,p), Sigma=Sigma)
y = my.mvrnorm(n=1, mu=rep(0,100)+X%*%beta.star, Sigma=v.star*diag(100))
# apply LASSO
index.vec = 1:50
mod1 = glmnet(X,y)
(true.lam = lambda.fnzero(mod1, index=index.vec))
nperm = 1000
lam.vec = rep(0, nperm)
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
hist(lam.vec, xlim=c(0,max(lam.vec, true.lam)))
abline(v=true.lam, lwd=2, col="Red")
(pval = sum(true.lam<lam.vec)/nperm)
index.vec = 11:50
mod1 = glmnet(X,y)
(true.lam = lambda.fnzero(mod1, index=index.vec))
# consider permutations
nperm = 1000
lam.vec = rep(0, nperm)
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
hist(lam.vec, xlim=c(0,max(lam.vec, true.lam)))
abline(v=true.lam, lwd=2, col="Red")
(pval = sum(true.lam<lam.vec)/nperm)
names(mod1)
?glmnet
mod1$lambda.min
cvmod1 - cv.glmnet(X,y)
cvmod1 = cv.glmnet(X,y)
beta1 = coef(mod1, lambda=cvmod1$lambda.min)
beta1
beta1 = coef(mod1, lambda=cvmod1$lambda.1se)
dim(beta1)
beta1 = coef(mod1, s=cvmod1$lambda.1se)
dim(beta1)
beta1
icvmod1 = cv.glmnet(X,iy)
ibeta1 = coef(imod1, s=icvmod1$lambda.1se)
ibeta1
ibeta1 = coef(imod1, s=icvmod1$lambda.min)
ibeta1
mod1 = glmnet(X,y)
cvmod1 = cv.glmnet(X,y)
beta1 = coef(mod1, s=cvmod1$lambda.min)
true.lam = cvmod1$lambda.min
true.lam
nperm = 1000
lam.vec = rep(0, nperm)
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
icvmod1 = cv.glmnet(X,iy)
lam.vec[i] = icvmod1$lam.min
#lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
icvmod1 = cv.glmnet(X,iy)
lam.vec[i] = icvmod1$lambda.min
#lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
hist(lam.vec, xlim=c(0,max(lam.vec, true.lam)))
abline(v=true.lam, lwd=2, col="Red")
(pval = sum(true.lam<lam.vec)/nperm)
lam.vec
true.lam
n = 100; p = 50
v.star = 1
beta.star = c(sample(0, 10, replace=T), rep(0,40))
Sigma = diag(p)
X = my.mvrnorm(n=n, mu=rep(0,p), Sigma=Sigma)
y = my.mvrnorm(n=1, mu=rep(0,100)+X%*%beta.star, Sigma=v.star*diag(100))
# apply LASSO
index.vec = 11:50
mod1 = glmnet(X,y)
cvmod1 = cv.glmnet(X,y)
beta1 = coef(mod1, s=cvmod1$lambda.min)
#(true.lam = lambda.fnzero(mod1, index=index.vec))
true.lam = cvmod1$lambda.min
true.lam
nperm = 100
lam.vec = rep(0, nperm)
for(i in 1:nperm){
iy = sample(y, n, replace=F)
imod1 = glmnet(X, iy)
icvmod1 = cv.glmnet(X,iy)
lam.vec[i] = icvmod1$lambda.min
#lam.vec[i] = lambda.fnzero(imod1, index=index.vec)
}
lam.vec
setwd("C:/Study/My projects/Quantiles/Codes/SBM")
rm(list=ls());
library(inline)
library(Rcpp)
library(RcppArmadillo)
library(RcppEigen)
library(fda.usc)
sourceCpp("ProjQuantNew.cpp", verbose=TRUE, rebuild=FALSE);
## function to compute outlier score
outlier.score = function(X, k=NULL, alpha){
n = nrow(X)
if(is.null(k)){
#k = floor(.1*n)
k = floor(sqrt(n))
}
depth.vec = rep(0,n)
knn.vec = rep(0,n)
# calculate distance matrix for full data
dist.mat = as.matrix(dist(X))
# get depth and knn average dist for all data
for(i in 1:n){
depth.vec[i] = ProjQuantileDepthMod(X[-i,], X[i,], .5)
ik = order(dist.mat[i,])[2:(k+1)]
knn.vec[i] = mean(dist.mat[i,ik])
}
lknn = log(knn.vec)
lhtped = -log(depth.vec)
return(alpha*lknn + (1-alpha)*lhtped)
}
sourceCpp("ProjQuantNew.cpp", verbose=TRUE, rebuild=FALSE);
ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5)
set.seed(11252014)
require(FastHCS)
data(DnaAlteration)
nsplit = 1e4
n = nrow(DnaAlteration)
ntest = floor(n/10)
test = sample(1:n, ntest, replace=F)
itest = as.matrix(DnaAlteration[test,])
itrain = as.matrix(DnaAlteration[-test,])
depth0 = rep(0,ntest); depth1 = depth0
ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5)
j=1
ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5)
WtProjQuantMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5)
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = -log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5))
depth1[j] = -log(ProjQuantileDepthMod(itrain[which(itrain[,1]==1),-1], itest[j,-1], .5))
}
depth0
depth1
EPQD = function(X, xx){
p = ncol(X)
Fuxu.vec = rep(0,100)
for(iu in 1:100){
u = runif(p,-1,1); u = u/sqrt(sum(u^2))
uecdf = ecdf(X%*%u)
Fuxu.vec[iu] = uecdf(xx%*%u)
}
1/(1+max(abs(Fuxu.vec-.5)))
}
## function to compute outlier score
outlier.score = function(X, type, k=NULL, alpha){
n = nrow(X)
if(is.null(k)){
#k = floor(.1*n)
k = floor(sqrt(n))
}
depth.vec = rep(0,n)
knn.vec = rep(0,n)
# calculate distance matrix for full data
dist.mat = as.matrix(dist(X))
# get depth and knn average dist for all data
for(i in 1:n){
if(type==1){
depth.vec[i] = ProjQuantileDepthMod(X[-i,], X[i,], .5)
}
else{
depth.vec[i] = EPQD(X[-i,], X[i,])
}
ik = order(dist.mat[i,])[2:(k+1)]
knn.vec[i] = mean(dist.mat[i,ik])
}
lknn = log(knn.vec)
lhtped = -log(depth.vec)
return(alpha*lknn + (1-alpha)*lhtped)
}
## simulated data
## Setup 1... bivariate normal.. 5% contamination far away
set.seed(11182014)
X1 = matrix(rnorm(950), ncol=2)
X2 = matrix(rnorm(50)+10, ncol=2)
Xa = rbind(X1,X2)
cols = c(rep("darkgreen",475), rep("darkred", 25))
# writeup plots
score1 = outlier.score(Xa, type=1, alpha=.05)
score2 = outlier.score(Xa, type=1, alpha=.5)
score3 = outlier.score(Xa, type=1, alpha=.95)
cols = c(rep("green",475), rep("red", 25))
par(mfrow=c(1,3))
plot(score1, col=cols, pch=19, cex=.8,
main="alpha=0.05", ylab="outlier score")
plot(score2, col=cols, pch=19, cex=.8,
main="alpha=0.5", ylab="outlier score")
plot(score3, col=cols, pch=19, cex=.8,
main="alpha=0.95", ylab="outlier score")
par(mfrow=c(1,1))
X1 = matrix(rnorm(950), ncol=2)
X2 = matrix(rnorm(50)+sample(c(6:10, -10:-6), 50, replace=T), ncol=2)
label.vec = c(rep("1",475), rep("2", 25))
Xb = rbind(X1,X2)
cols = c(rep("darkgreen",475), rep("darkred", 25))
# writeup plots
score1 = outlier.score(Xb, type=1, alpha=.05)
score2 = outlier.score(Xb, type=1, alpha=.5)
score3 = outlier.score(Xb, type=1, alpha=.95)
cols = c(rep("green",475), rep("red", 25))
par(mfrow=c(1,3))
plot(score1, col=cols, pch=19, cex=.8,
main="alpha=0.05", ylab="outlier score")
plot(score2, col=cols, pch=19, cex=.8,
main="alpha=0.5", ylab="outlier score")
plot(score3, col=cols, pch=19, cex=.8,
main="alpha=0.95", ylab="outlier score")
par(mfrow=c(1,1))
par(mfrow=c(2,2))
plot(lm(stack.loss~., data=stackloss))
par(mfrow=c(1,1))
score.vec = outlier.score(as.matrix(stackloss[,-4]),
type=1, alpha=.8)
plot(score.vec, pch=19, cex=.5)
abline(h=quantile(score.vec,.9), lty=2, lwd=2)
# writeup plots
X = as.matrix(stackloss[,-4])
score1 = outlier.score(X, type=1, alpha=.05)
score2 = outlier.score(X, type=1, alpha=.5)
score3 = outlier.score(X, type=1, alpha=.95)
par(mfrow=c(1,3))
plot(score1, pch=19, cex=.8,
main="alpha=0.05", ylab="outlier score")
plot(score2, pch=19, cex=.8,
main="alpha=0.5", ylab="outlier score")
plot(score3, pch=19, cex=.8,
main="alpha=0.95", ylab="outlier score")
par(mfrow=c(1,1))
require(robustbase)
score.vec = outlier.score(as.matrix(hbk[,-4]),
type=1, alpha=.2)
plot(score.vec, pch=19, cex=.5)
#abline(h=quantile(score.vec,.9), lty=2, lwd=2)
# writeup plots
X = as.matrix(hbk[,-4])
score1 = outlier.score(X, type=1, alpha=.05)
score2 = outlier.score(X, type=1, alpha=.5)
score3 = outlier.score(X, type=1, alpha=.95)
par(mfrow=c(1,3))
plot(score1, pch=19, cex=.8,
main="alpha=0.05", ylab="outlier score"); abline(v=14, lty=2)
plot(score2, pch=19, cex=.8,
main="alpha=0.5", ylab="outlier score"); abline(v=14, lty=2)
plot(score3, pch=19, cex=.8,
main="alpha=0.95", ylab="outlier score"); abline(v=14, lty=2)
par(mfrow=c(1,1))
class.pred = (depth0 > depth1)
pred.miss = sum(test[,1] == class.pred)
class.pred
test
itest[,1]
depth0
depth1
test = sample(1:n, ntest, replace=F)
itest = as.matrix(DnaAlteration[test,])
itrain = as.matrix(DnaAlteration[-test,])
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = -log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5))
depth1[j] = -log(ProjQuantileDepthMod(itrain[which(itrain[,1]==1),-1], itest[j,-1], .5))
}
depth0
depth1
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5))
depth1[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==1),-1], itest[j,-1], .5))
}
depth0
depth1
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = log(ProjQuantileDepth(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5))
depth1[j] = log(ProjQuantileDepth(itrain[which(itrain[,1]==1),-1], itest[j,-1], .5))
}
which(itrain[,1]==0)
itrain[,1]
pred.miss = sum(itest[,1] == class.pred)
pred.miss
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5))
depth1[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==1),-1], itest[j,-1], .5))
}
class.pred = (depth0 > depth1)
pred.miss = sum(itest[,1] == class.pred)
pred.miss
class.pred
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .9))
depth1[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==1),-1], itest[j,-1], .9))
}
class.pred = (depth0 > depth1)
pred.miss = sum(itest[,1] == class.pred)
pred.miss
class.pred
depth0
depth1
depth0[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], 1))
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .1))
depth1[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==1),-1], itest[j,-1], .1))
}
class.pred = (depth0 > depth1)
pred.miss = sum(itest[,1] == class.pred)
depth0
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .2))
depth1[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==1),-1], itest[j,-1], .2))
}
class.pred = (depth0 > depth1)
pred.miss = sum(itest[,1] == class.pred)
depth0
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .99))
depth1[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==1),-1], itest[j,-1], .99))
}
class.pred = (depth0 > depth1)
pred.miss = sum(itest[,1] == class.pred)
depth0
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5))
depth1[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==1),-1], itest[j,-1], .5))
}
class.pred = (depth0 > depth1)
pred.miss = sum(itest[,1] == class.pred)
depth0
depth1
test = sample(1:n, ntest, replace=F)
itest = as.matrix(DnaAlteration[test,])
itrain = as.matrix(DnaAlteration[-test,])
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5))
depth1[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==1),-1], itest[j,-1], .5))
}
depth0
depth1
class.pred = (depth0 > depth1)
pred.miss = sum(itest[,1] == class.pred)
class.pred
itrain[which(itrain[,1]==0),1]
sourceCpp("ProjQuantNew.cpp", verbose=TRUE, rebuild=FALSE);
sourceCpp("ProjQuantNew.cpp", verbose=TRUE, rebuild=FALSE);
sourceCpp("ProjQuantNew.cpp", verbose=TRUE, rebuild=FALSE);
depth0 = rep(0,ntest); depth1 = depth0
for(j in 1:ntest){
depth0[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==0),-1], itest[j,-1], .5))
depth1[j] = log(ProjQuantileDepthMod(itrain[which(itrain[,1]==1),-1], itest[j,-1], .5))
}
depth0
depth1
class.pred = (depth0 > depth1)
pred.miss = sum(itest[,1] == class.pred)
class.pred
